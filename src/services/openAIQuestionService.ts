import OpenAI from 'openai';
import dotenv from 'dotenv';

dotenv.config();

const openai = new OpenAI({
  apiKey: process.env.OPENAI_KEY
}); 

const SYSTEM_PROMPT = `Eres Bernardita, una asistente virtual emp√°tica de GetMemori, especializada en preservar historias de vida personales y familiares.

      Tu funci√≥n es guiar al usuario a trav√©s de dos etapas principales:
      1. **Onboarding**: Recopilar informaci√≥n inicial b√°sica como su nombre completo, fecha y lugar de nacimiento, y verificar si est√° listo/a para iniciar el viaje por sus memorias.
      2. **Infancia**: Explorar en detalle la etapa de la infancia del usuario, utilizando un checklist estructurado y el historial de la conversaci√≥n para profundizar en temas relevantes.

      ### Objetivos principales:
      1. Crear una experiencia c√°lida y significativa mientras documentas la historia de vida del usuario.
      2. Guiar la conversaci√≥n de manera natural, proactiva y emp√°tica, adapt√°ndote a la informaci√≥n ya compartida.
      3. Usar preguntas espec√≠ficas y detalladas para enriquecer la narrativa, priorizando temas que el usuario mencione espont√°neamente y cubriendo lagunas con el checklist.
      4. Validar las emociones y recuerdos del usuario, mostrando inter√©s genuino.

      ### Pautas para la interacci√≥n:
      - Mant√©n un tono conversacional, c√°lido y respetuoso en todo momento.
      - Haz preguntas abiertas y detalladas, pero mant√©n las respuestas claras y concisas.
      - Si el usuario comparte algo emotivo o significativo, responde con empat√≠a y fomenta la profundizaci√≥n en ese tema.
      - Durante el Onboarding, gu√≠a al usuario para pasar a la etapa de Infancia de forma natural.
      - En la etapa de Infancia, utiliza el historial y el checklist para hacer preguntas m√°s personalizadas y completas.
      - Aseg√∫rate de construir una narrativa coherente y rica con la informaci√≥n recopilada.

      ### Recuerda:
      - Ya tienes una base de informaci√≥n inicial (nombre, lugar/fecha de nacimiento, etc.), √∫sala para personalizar tus preguntas.
      - GetMemori busca crear un espacio seguro y c√≥modo donde las personas puedan compartir sus memorias m√°s valiosas.
      - S√© proactiva y no esperes a que el usuario te pregunte. Gu√≠a la conversaci√≥n de manera intuitiva.

      Tu objetivo final es recopilar informaci√≥n rica y detallada para construir una biograf√≠a √∫nica y emocionalmente significativa. ¬°Haz que el usuario se sienta escuchado y valorado!`;

export const generateQuestionResponse = async ({
  summary,
  history,
  message,
  sendTemplate,
}: {
  summary: string;
  history: string[]; // √öltimos 2 mensajes del historial [pen√∫ltimo del usuario, √∫ltimo del bot]
  message: string; // Mensaje m√°s reciente del usuario
  sendTemplate: boolean; // Indica si se debe enviar el template de WhatsApp, para que LLM tenga contexto de que ya se complet√≥ la pregunta
}): Promise<string> => {

  let userPrompt = `
          Resumen de la pregunta:
          ${summary}

          √öltimos mensajes de la conversaci√≥n:
          - Usuario: "${history[0]}" (pen√∫ltimo mensaje del usuario)
          - Bot: "${history[1]}" (√∫ltima respuesta del bot)

          Mensaje m√°s reciente del usuario:
          "${message}"

          Bas√°ndote en el resumen de la pregunta, los mensajes recientes y el mensaje m√°s reciente del usuario:
          - Responde de manera c√°lida, emp√°tica y enfocada en profundizar en los detalles relacionados con la pregunta.
          - Si el mensaje reciente del usuario incluye nuevos detalles, fomenta que ampl√≠e m√°s sobre esos puntos espec√≠ficos.
          - Si el mensaje reciente no aporta detalles nuevos, utiliza el resumen y el historial para hacer preguntas abiertas que inviten a recordar momentos o aspectos m√°s profundos relacionados con la pregunta.

          IMPORTANTE:
          - Personaliza la respuesta para que sea relevante a la pregunta actual.
          - Formula preguntas espec√≠ficas pero abiertas que ayuden a explorar recuerdos m√°s detallados o emociones relacionadas.
          - Mant√©n un tono c√°lido, curioso y amigable, evitando abrumar con demasiados temas.
          - Ayuda al usuario a organizar sus ideas si menciona varios temas dispersos, conect√°ndolos de forma natural.
          - No te excedas con la cantidad de preguntas. No abrumes con tanto texto.
          - Si sendTemplate es true, significa que el usuario tiene la opci√≥n de pasar a la siguiente pregunta. En este caso, mant√©n el mensaje breve y conciso, sin profundizar demasiado, para darle espacio a decidir si quiere continuar o no.
          -- sendTemplate: ${sendTemplate}
          
        EJEMPLO: 

        USUARIO: "Claro, me acuerdo que cuando chico siempre jugaba con la bicicleta y me encantaba ir a jugar a un bosque all√° cerca de la casa. Cuando chico yo viv√≠a en una casa en un sector llamado Esmeralda. Viv√≠a con mis t√≠os, con mi mam√°, con mi hermano y con mis primos. Era una locura porque siempre jug√°bamos Eran muchos primos, una familia muy unida. " 
        RESPUESTA_ESPERADA: "¬°Qu√© bonito recordar esos tiempos en Esmeralda! Suena como si tu infancia estuviera llena de alegr√≠a, aventuras y momentos especiales junto a tus primos. üå≥‚ú®
        La bicicleta y el bosque deben haber sido un escenario perfecto para risas y travesuras. ¬øRecuerdas alguna an√©cdota divertida o juego que haya dejado una huella especial en ti? üö¥‚Äç‚ôÇÔ∏èüòä"

        EJEMPLO 2: 

        CONTEXTO: "si el usuario comenta que esta perdido, o que no entendio el flujo de la conversaci√≥n, o que no sabe que hacer, o que no entiende el checklist, etc."
        RESPUESTA_ESPERADA: "¬°No te preocupes! Estoy aqu√≠ para ayudarte.  üåê"
  `;

  console.log(userPrompt);

  try {
    const completion = await openai.chat.completions.create({
      messages: [
        { role: "system", content: SYSTEM_PROMPT },
        { role: "user", content: userPrompt },
      ],
      model: "gpt-4o-mini",
      temperature: 0.7,
      max_tokens: 500,
    });

    return (
      completion.choices[0]?.message?.content ||
      'Lo siento, no pude generar una respuesta adecuada.'
    );
  } catch (error) {
    console.error('Error al generar respuesta de IA:', error);
    return 'Lo siento, ocurri√≥ un error al procesar tu mensaje. Por favor, intenta de nuevo.';
  }
};

export const generateQuestionMessage = async (question: string): Promise<string> => {
  const userPrompt = `
Eres un asistente c√°lido y emp√°tico encargado de guiar conversaciones significativas. Genera un mensaje c√°lido y cercano que introduzca la siguiente pregunta al usuario.

### FORMATO ESPERADO:
- Una l√≠nea introductoria amigable y c√°lida.
- La palabra "PREGUNTA:" seguida de un salto de l√≠nea.
- La pregunta exacta, tal como se recibe, sin modificarla.

### EJEMPLO DE RESPUESTA:
"
Vamos a explorar los hermosos recuerdos de tu infancia üåà  
- salto de linea
- salto de linea
*PREGUNTA:*  
- salto de linea
- salto de linea
*¬øD√≥nde naciste y c√≥mo era el lugar donde creciste?*
"

### INSTRUCCIONES:
1. La introducci√≥n debe ser c√°lida y cercana, invitando al usuario a reflexionar.
2. La palabra "PREGUNTA:" debe aparecer en may√∫sculas y seguida por dos saltos de l√≠nea.
3. La pregunta debe aparecer inmediatamente despu√©s, sin modificarla en absoluto.
4. No devuelvas explicaciones ni texto adicional, solo el mensaje completo listo para ser enviado.

### PREGUNTA:
"${question}"

### TU TAREA:
Genera el mensaje seg√∫n las instrucciones y en el formato indicado.
`;


  const completion = await openai.chat.completions.create({
    messages: [{ role: "system", content: SYSTEM_PROMPT }, { role: "user", content: userPrompt }],
    model: "gpt-4o-mini", 
    temperature: 0.7,
    max_tokens: 500,
  });

  return completion.choices[0]?.message?.content || 'Lo siento, no pude generar una respuesta.';
};



interface ValidationResult {
  summary: string; // Resumen generado por el LLM
  validators: {
    family: boolean; // Indicador si se habl√≥ lo suficiente sobre la familia
    friends: boolean; // Indicador si se habl√≥ lo suficiente sobre los amigos
    school: boolean; // Indicador si se habl√≥ lo suficiente sobre la escuela
  };
}

export const summarizeConversationHistory = async (
  history: string,
  validationQuestions: string[] = ['familia', 'amigos', 'escuela']
): Promise<ValidationResult> => {
  try {
    const completion = await openai.chat.completions.create({
      messages: [
        {
          role: "system",
          content: `
            Eres un asistente experto en resumir conversaciones y validar contenido. 
            Tu tarea es doble:
            1. Generar un resumen conciso de la conversaci√≥n proporcionada, manteniendo los detalles importantes sobre la historia de vida del usuario. 
            El resumen no debe exceder los 200 tokens.
            2. Validar si la conversaci√≥n incluye informaci√≥n suficiente sobre los siguientes temas:
            - Familia
            - Amigos
            - Escuela
            Responde con un JSON estructurado que contenga el resumen y una validaci√≥n booleana para cada tema.
            ejemplo:
            {
              "summary": "Resumen de la conversaci√≥n",
              "validators": {
                "family": true,
                "friends": false,
                "school": true
              }
            }
          `,
        },
        {
          role: "user",
          content: `Por favor, realiza estas tareas sobre la siguiente conversaci√≥n:\n${history}`,
        },
      ],
      model: "gpt-4o-mini",
      temperature: 0.7,
      max_tokens: 250, // Aseguramos espacio para un output estructurado
    });

    // Parsear el resultado generado por el modelo
    const response = completion.choices[0]?.message?.content;
    console.log(response);
    // Intentar convertir la salida a JSON estructurado
    try {
      const parsedResult: ValidationResult = JSON.parse(response || '');
      return parsedResult;
    } catch (parseError) {
      console.error('Error al parsear la respuesta del modelo:', parseError);
      return {
        summary: 'No se pudo generar un resumen v√°lido.',
        validators: {
          family: false,
          friends: false,
          school: false,
        },
      };
    }
  } catch (error) {
    console.error('Error al generar el resumen y validar la conversaci√≥n:', error);
    return {
      summary: 'Error al generar el resumen.',
      validators: {
        family: false,
        friends: false,
        school: false,
      },
    };
  }
};
