import OpenAI from 'openai';
import dotenv from 'dotenv';

dotenv.config();

const openai = new OpenAI({
  apiKey: process.env.OPENAI_KEY
}); 

const SYSTEM_PROMPT = `Eres Bernardita, una asistente virtual emp치tica de GetMemori, especializada en preservar historias de vida personales y familiares.

      Tu funci칩n es guiar al usuario a trav칠s de dos etapas principales:
      1. **Onboarding**: Recopilar informaci칩n inicial b치sica como su nombre completo, fecha y lugar de nacimiento, y verificar si est치 listo/a para iniciar el viaje por sus memorias.
      2. **Infancia**: Explorar en detalle la etapa de la infancia del usuario, utilizando un checklist estructurado y el historial de la conversaci칩n para profundizar en temas relevantes.

      ### Objetivos principales:
      1. Crear una experiencia c치lida y significativa mientras documentas la historia de vida del usuario.
      2. Guiar la conversaci칩n de manera natural, proactiva y emp치tica, adapt치ndote a la informaci칩n ya compartida.
      3. Usar preguntas espec칤ficas y detalladas para enriquecer la narrativa, priorizando temas que el usuario mencione espont치neamente y cubriendo lagunas con el checklist.
      4. Validar las emociones y recuerdos del usuario, mostrando inter칠s genuino.

      ### Pautas para la interacci칩n:
      - Mant칠n un tono conversacional, c치lido y respetuoso en todo momento.
      - Haz preguntas abiertas y detalladas, pero mant칠n las respuestas claras y concisas.
      - Si el usuario comparte algo emotivo o significativo, responde con empat칤a y fomenta la profundizaci칩n en ese tema.
      - Durante el Onboarding, gu칤a al usuario para pasar a la etapa de Infancia de forma natural.
      - En la etapa de Infancia, utiliza el historial y el checklist para hacer preguntas m치s personalizadas y completas.
      - Aseg칰rate de construir una narrativa coherente y rica con la informaci칩n recopilada.

      ### Recuerda:
      - Ya tienes una base de informaci칩n inicial (nombre, lugar/fecha de nacimiento, etc.), 칰sala para personalizar tus preguntas.
      - GetMemori busca crear un espacio seguro y c칩modo donde las personas puedan compartir sus memorias m치s valiosas.
      - S칠 proactiva y no esperes a que el usuario te pregunte. Gu칤a la conversaci칩n de manera intuitiva.

      Tu objetivo final es recopilar informaci칩n rica y detallada para construir una biograf칤a 칰nica y emocionalmente significativa. 춰Haz que el usuario se sienta escuchado y valorado!`;

export const generateQuestionResponse = async ({
  summary,
  history,
  message,
}: {
  summary: string;
  history: string[]; // 칔ltimos 2 mensajes del historial [pen칰ltimo del usuario, 칰ltimo del bot]
  message: string; // Mensaje m치s reciente del usuario
}): Promise<string> => {

  let userPrompt = `
          Resumen de la pregunta:
          ${summary}

          칔ltimos mensajes de la conversaci칩n:
          - Usuario: "${history[0]}" (pen칰ltimo mensaje del usuario)
          - Bot: "${history[1]}" (칰ltima respuesta del bot)

          Mensaje m치s reciente del usuario:
          "${message}"

          Bas치ndote en el resumen de la pregunta, los mensajes recientes y el mensaje m치s reciente del usuario:
          - Responde de manera c치lida, emp치tica y enfocada en profundizar en los detalles relacionados con la pregunta.
          - Si el mensaje reciente del usuario incluye nuevos detalles, fomenta que ampl칤e m치s sobre esos puntos espec칤ficos.
          - Si el mensaje reciente no aporta detalles nuevos, utiliza el resumen y el historial para hacer preguntas abiertas que inviten a recordar momentos o aspectos m치s profundos relacionados con la pregunta.

          IMPORTANTE:
          - Personaliza la respuesta para que sea relevante a la pregunta actual.
          - Formula preguntas espec칤ficas pero abiertas que ayuden a explorar recuerdos m치s detallados o emociones relacionadas.
          - Mant칠n un tono c치lido, curioso y amigable, evitando abrumar con demasiados temas.
          - Ayuda al usuario a organizar sus ideas si menciona varios temas dispersos, conect치ndolos de forma natural.
  `;

  console.log(userPrompt);

  try {
    const completion = await openai.chat.completions.create({
      messages: [
        { role: "system", content: SYSTEM_PROMPT },
        { role: "user", content: userPrompt },
      ],
      model: "gpt-4o-mini",
      temperature: 0.7,
      max_tokens: 500,
    });

    return (
      completion.choices[0]?.message?.content ||
      'Lo siento, no pude generar una respuesta adecuada.'
    );
  } catch (error) {
    console.error('Error al generar respuesta de IA:', error);
    return 'Lo siento, ocurri칩 un error al procesar tu mensaje. Por favor, intenta de nuevo.';
  }
};

export const generateQuestionMessage = async (question: string): Promise<string> => {
  const userPrompt = `
Eres un asistente c치lido y emp치tico encargado de guiar conversaciones significativas. Genera un mensaje c치lido y cercano que introduzca la siguiente pregunta al usuario.

### FORMATO ESPERADO:
- Una l칤nea introductoria amigable y c치lida.
- La palabra "PREGUNTA:" seguida de un salto de l칤nea.
- La pregunta exacta, tal como se recibe, sin modificarla.

### EJEMPLO DE RESPUESTA:
"
Vamos a explorar los hermosos recuerdos de tu infancia 游깯  
- salto de linea
- salto de linea
*PREGUNTA:*  
- salto de linea
- salto de linea
*쮻칩nde naciste y c칩mo era el lugar donde creciste?*
"

### INSTRUCCIONES:
1. La introducci칩n debe ser c치lida y cercana, invitando al usuario a reflexionar.
2. La palabra "PREGUNTA:" debe aparecer en may칰sculas y seguida por dos saltos de l칤nea.
3. La pregunta debe aparecer inmediatamente despu칠s, sin modificarla en absoluto.
4. No devuelvas explicaciones ni texto adicional, solo el mensaje completo listo para ser enviado.

### PREGUNTA:
"${question}"

### TU TAREA:
Genera el mensaje seg칰n las instrucciones y en el formato indicado.
`;


  const completion = await openai.chat.completions.create({
    messages: [{ role: "system", content: SYSTEM_PROMPT }, { role: "user", content: userPrompt }],
    model: "gpt-4o-mini", 
    temperature: 0.7,
    max_tokens: 500,
  });

  return completion.choices[0]?.message?.content || 'Lo siento, no pude generar una respuesta.';
};



interface ValidationResult {
  summary: string; // Resumen generado por el LLM
  validators: {
    family: boolean; // Indicador si se habl칩 lo suficiente sobre la familia
    friends: boolean; // Indicador si se habl칩 lo suficiente sobre los amigos
    school: boolean; // Indicador si se habl칩 lo suficiente sobre la escuela
  };
}

export const summarizeConversationHistory = async (
  history: string,
  validationQuestions: string[] = ['familia', 'amigos', 'escuela']
): Promise<ValidationResult> => {
  try {
    const completion = await openai.chat.completions.create({
      messages: [
        {
          role: "system",
          content: `
            Eres un asistente experto en resumir conversaciones y validar contenido. 
            Tu tarea es doble:
            1. Generar un resumen conciso de la conversaci칩n proporcionada, manteniendo los detalles importantes sobre la historia de vida del usuario. 
            El resumen no debe exceder los 200 tokens.
            2. Validar si la conversaci칩n incluye informaci칩n suficiente sobre los siguientes temas:
            - Familia
            - Amigos
            - Escuela
            Responde con un JSON estructurado que contenga el resumen y una validaci칩n booleana para cada tema.
            ejemplo:
            {
              "summary": "Resumen de la conversaci칩n",
              "validators": {
                "family": true,
                "friends": false,
                "school": true
              }
            }
          `,
        },
        {
          role: "user",
          content: `Por favor, realiza estas tareas sobre la siguiente conversaci칩n:\n${history}`,
        },
      ],
      model: "gpt-4o-mini",
      temperature: 0.7,
      max_tokens: 250, // Aseguramos espacio para un output estructurado
    });

    // Parsear el resultado generado por el modelo
    const response = completion.choices[0]?.message?.content;
    console.log(response);
    // Intentar convertir la salida a JSON estructurado
    try {
      const parsedResult: ValidationResult = JSON.parse(response || '');
      return parsedResult;
    } catch (parseError) {
      console.error('Error al parsear la respuesta del modelo:', parseError);
      return {
        summary: 'No se pudo generar un resumen v치lido.',
        validators: {
          family: false,
          friends: false,
          school: false,
        },
      };
    }
  } catch (error) {
    console.error('Error al generar el resumen y validar la conversaci칩n:', error);
    return {
      summary: 'Error al generar el resumen.',
      validators: {
        family: false,
        friends: false,
        school: false,
      },
    };
  }
};
