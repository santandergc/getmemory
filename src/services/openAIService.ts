import OpenAI from 'openai';
import dotenv from 'dotenv';

dotenv.config();

const openai = new OpenAI({
  apiKey: process.env.OPENAI_KEY
}); 

const SYSTEM_PROMPT = `Eres Bernardita, una asistente virtual emp√°tica de GetMemori, especializada en preservar historias de vida personales y familiares.

      Tu funci√≥n es guiar al usuario a trav√©s de dos etapas principales:
      1. **Onboarding**: Recopilar informaci√≥n inicial b√°sica como su nombre completo, fecha y lugar de nacimiento, y verificar si est√° listo/a para iniciar el viaje por sus memorias.
      2. **Infancia**: Explorar en detalle la etapa de la infancia del usuario, utilizando un checklist estructurado y el historial de la conversaci√≥n para profundizar en temas relevantes.

      ### Objetivos principales:
      1. Crear una experiencia c√°lida y significativa mientras documentas la historia de vida del usuario.
      2. Guiar la conversaci√≥n de manera natural, proactiva y emp√°tica, adapt√°ndote a la informaci√≥n ya compartida.
      3. Usar preguntas espec√≠ficas y detalladas para enriquecer la narrativa, priorizando temas que el usuario mencione espont√°neamente y cubriendo lagunas con el checklist.
      4. Validar las emociones y recuerdos del usuario, mostrando inter√©s genuino.

      ### Pautas para la interacci√≥n:
      - Mant√©n un tono conversacional, c√°lido y respetuoso en todo momento.
      - Haz preguntas abiertas y detalladas, pero mant√©n las respuestas claras y concisas.
      - Si el usuario comparte algo emotivo o significativo, responde con empat√≠a y fomenta la profundizaci√≥n en ese tema.
      - Durante el Onboarding, gu√≠a al usuario para pasar a la etapa de Infancia de forma natural.
      - En la etapa de Infancia, utiliza el historial y el checklist para hacer preguntas m√°s personalizadas y completas.
      - Aseg√∫rate de construir una narrativa coherente y rica con la informaci√≥n recopilada.

      ### Recuerda:
      - Ya tienes una base de informaci√≥n inicial (nombre, lugar/fecha de nacimiento, etc.), √∫sala para personalizar tus preguntas.
      - GetMemori busca crear un espacio seguro y c√≥modo donde las personas puedan compartir sus memorias m√°s valiosas.
      - S√© proactiva y no esperes a que el usuario te pregunte. Gu√≠a la conversaci√≥n de manera intuitiva.

      Tu objetivo final es recopilar informaci√≥n rica y detallada para construir una biograf√≠a √∫nica y emocionalmente significativa. ¬°Haz que el usuario se sienta escuchado y valorado!`;

export const generateAIResponse = async ({ 
  history,
  checklist,
  message 
}: {
  history: any;
  checklist: any;
  message: string;
}) => {  
  const userPrompt = `
        Historial de la conversaci√≥n hasta ahora:
        ${history}

        Checklist de temas clave:
        ${JSON.stringify(checklist)}

        Mensaje m√°s reciente del usuario:
        "${message}"

        Bas√°ndote en esta informaci√≥n, responde de manera interactiva. Profundiza en los detalles mencionados y formula preguntas abiertas que exploren aspectos no cubiertos, asegur√°ndote de mantener un tono c√°lido y emp√°tico.
        IMPORTANTE: No uses la lista de verificaci√≥n como gu√≠a r√≠gida, sino como una referencia para profundizar en los temas clave. Y sobre todo, NO ABRUMES con tanto texto y tanta pregunta.

        EJEMPLO: 

        USUARIO: "Transcribir audio ... " 
        RESPUESTA_ESPERADA: "¬°Qu√© bonito recordar esos tiempos en Esmeralda! Suena como si tu infancia estuviera llena de alegr√≠a, aventuras y momentos especiales junto a tus primos. üå≥‚ú®
        La bicicleta y el bosque deben haber sido un escenario perfecto para risas y travesuras. ¬øRecuerdas alguna an√©cdota divertida o juego que haya dejado una huella especial en ti? üö¥‚Äç‚ôÇÔ∏èüòä"

        EJEMPLO 2: 

        CONTEXTO: "si el usuario comenta que esta perdido, o que no entendio el flujo de la conversaci√≥n, o que no sabe que hacer, o que no entiende el checklist, etc."
        RESPUESTA_ESPERADA: "¬°No te preocupes! Estoy aqu√≠ para ayudarte.  üåê"
  `;

  try {
    const completion = await openai.chat.completions.create({
      messages: [
        { role: "system", content: SYSTEM_PROMPT },
        { role: "user", content: userPrompt }
      ],
      model: "gpt-4o-mini",
      temperature: 0.7,
      max_tokens: 500
    });

    return completion.choices[0].message.content || 'Lo siento, no pude generar una respuesta.';
  } catch (error) {
    console.error('Error al generar respuesta de IA:', error);
    return 'Lo siento, ha ocurrido un error. ¬øPodr√≠as intentar escribir tu mensaje nuevamente?';
  }
}

export const generateInfanciaResponse = async ({
  summary,
  history,
  message,
  completedCounter,
  isCompleted
}: {
  summary: string; // Resumen acumulado de la etapa
  history: string[]; // √öltimos 2 mensajes del historial [pen√∫ltimo del usuario, √∫ltimo del bot]
  message: string; // Mensaje m√°s reciente del usuario
  completedCounter: number; // Cantidad de temas completados del checklist
  isCompleted: boolean; // Indicador si la etapa ya est√° completada
}): Promise<string> => {

  let userPrompt = `
          Resumen de la etapa (Infancia):
          ${summary}

          √öltimos mensajes de la conversaci√≥n:
          - Usuario: "${history[0]}" (pen√∫ltimo mensaje del usuario)
          - Bot: "${history[1]}" (√∫ltima respuesta del bot)

          Mensaje m√°s reciente del usuario:
          "${message}"

          Bas√°ndote en el resumen de la etapa, los mensajes recientes, y el mensaje m√°s reciente del usuario:
          - Responde de manera c√°lida y emp√°tica.
          - Profundiza en los detalles mencionados en el mensaje reciente del usuario.
          - Si no hay nuevos detalles en el mensaje, utiliza el resumen o el historial para guiar la conversaci√≥n.
          - Formula una pregunta abierta que invite a compartir m√°s recuerdos, asegur√°ndote de no abrumar con demasiados temas.

          IMPORTANTE:
          - Personaliza la respuesta utilizando informaci√≥n relevante del resumen.
          - No repitas el historial directamente, pero √∫salo como contexto.
          - Prioriza un tono c√°lido, conversacional y curioso.
  `;
  if (completedCounter >= 3 && isCompleted) {
    userPrompt += `
          ----
          EXTRA: (considera esto solo si el usuario ya ha compartido suficiente informaci√≥n sobre su infancia) De todas formas debes seguir el sistema de preguntas del checklist, pero agrega un peque√±o mensaje que proponga y le pregunta si quiere que entremos en su etapa de adolescencia. 
          ejemplo: "... es emocionante hablar de tu infancia, me pregunto si quieres que comencemos a explorar tu etapa de adolescencia. ¬øQu√© te parece? 
          Puedes ser creativo en variar el mensaje, pero siempre respetando el tono c√°lido y emp√°tico.
          `;
  }

  try {
    const completion = await openai.chat.completions.create({
      messages: [
        { role: "system", content: SYSTEM_PROMPT },
        { role: "user", content: userPrompt },
      ],
      model: "gpt-4o-mini",
      temperature: 0.7,
      max_tokens: 500,
    });

    return (
      completion.choices[0]?.message?.content ||
      'Lo siento, no pude generar una respuesta adecuada.'
    );
  } catch (error) {
    console.error('Error al generar respuesta de IA:', error);
    return 'Lo siento, ocurri√≥ un error al procesar tu mensaje. Por favor, intenta de nuevo.';
  }
};



interface ValidationResult {
  summary: string; // Resumen generado por el LLM
  validators: {
    family: boolean; // Indicador si se habl√≥ lo suficiente sobre la familia
    friends: boolean; // Indicador si se habl√≥ lo suficiente sobre los amigos
    school: boolean; // Indicador si se habl√≥ lo suficiente sobre la escuela
  };
}

export const summarizeConversationHistory = async (
  history: string,
  validationQuestions: string[] = ['familia', 'amigos', 'escuela']
): Promise<ValidationResult> => {
  try {
    const completion = await openai.chat.completions.create({
      messages: [
        {
          role: "system",
          content: `
            Eres un asistente experto en resumir conversaciones y validar contenido. 
            Tu tarea es doble:
            1. Generar un resumen conciso de la conversaci√≥n proporcionada, manteniendo los detalles importantes sobre la historia de vida del usuario. 
            El resumen no debe exceder los 200 tokens.
            2. Validar si la conversaci√≥n incluye informaci√≥n suficiente sobre los siguientes temas:
            - Familia
            - Amigos
            - Escuela
            Responde con un JSON estructurado que contenga el resumen y una validaci√≥n booleana para cada tema.
            ejemplo:
            {
              "summary": "Resumen de la conversaci√≥n",
              "validators": {
                "family": true,
                "friends": false,
                "school": true
              }
            }
          `,
        },
        {
          role: "user",
          content: `Por favor, realiza estas tareas sobre la siguiente conversaci√≥n:\n${history}`,
        },
      ],
      model: "gpt-4o-mini",
      temperature: 0.7,
      max_tokens: 250, // Aseguramos espacio para un output estructurado
    });

    // Parsear el resultado generado por el modelo
    const response = completion.choices[0]?.message?.content;
    console.log(response);
    // Intentar convertir la salida a JSON estructurado
    try {
      const parsedResult: ValidationResult = JSON.parse(response || '');
      return parsedResult;
    } catch (parseError) {
      console.error('Error al parsear la respuesta del modelo:', parseError);
      return {
        summary: 'No se pudo generar un resumen v√°lido.',
        validators: {
          family: false,
          friends: false,
          school: false,
        },
      };
    }
  } catch (error) {
    console.error('Error al generar el resumen y validar la conversaci√≥n:', error);
    return {
      summary: 'Error al generar el resumen.',
      validators: {
        family: false,
        friends: false,
        school: false,
      },
    };
  }
};

export const analyzeStageTransitionIntent = async (message: string, history: string[], stage: string): Promise<string> => {
  try {
    console.log(history);
    const completion = await openai.chat.completions.create({
      messages: [
        {
          role: "system",
          content: `Eres un asistente experto en analizar intenciones en conversaciones.
            Clasifica esta respuesta del usuario en una de las siguientes categor√≠as: 
            - "afirmativa" (el usuario expl√≠citamente quiere empezar a explorar su etapa de ${stage} con frases como "s√≠, quiero avanzar", "listo para la ${stage}", o "quiero hablar de mi ${stage}").
            - "negativa" (el usuario expl√≠citamente indica que no quiere avanzar con frases como "no", "quiero seguir aqu√≠", o "prefiero hablar m√°s de esta etapa").
            - "ambigua" (el usuario no es claro, no responde directamente, o su respuesta es vaga).

            Una respuesta afirmativa debe contener frases claras y expl√≠citas. No puede ser ambigua o derivarse de contexto impl√≠cito.

            Devuelve solo una palabra: "afirmativa", "negativa" o "ambigua".
            `
        },
        {
          role: "user",
          content: `
          Historial de la conversaci√≥n hasta ahora:
          ${history}

          Mensaje m√°s reciente del usuario:
          "${message}"
          `
        }
      ],
      model: "gpt-4o-mini",
      temperature: 0.1,
      max_tokens: 10
    });

    return completion.choices[0]?.message?.content?.toLowerCase() || 'ambigua';
  } catch (error) {
    console.error('Error al analizar la intenci√≥n:', error);
    return 'ambigua';
  }
};

export const generateAdolescenciaResponse = async ({
  summary,
  history,
  message,
  completedCounter,
  isCompleted
}: {
  summary: string; // Resumen acumulado de la etapa
  history: string[]; // √öltimos 2 mensajes del historial [pen√∫ltimo del usuario, √∫ltimo del bot]
  message: string; // Mensaje m√°s reciente del usuario
  completedCounter: number; // Cantidad de temas completados del checklist
  isCompleted: boolean; // Indicador si la etapa ya est√° completada
}): Promise<string> => {
  // Construcci√≥n del prompt para el modelo
  let userPrompt = `
  Resumen de la etapa (Adolescencia):
  ${summary}

  √öltimos mensajes de la conversaci√≥n:
  - Usuario: "${history[0]}" (pen√∫ltimo mensaje del usuario)
  - Bot: "${history[1]}" (√∫ltima respuesta del bot)

  Mensaje m√°s reciente del usuario:
  "${message}"

  Bas√°ndote en el resumen de la etapa, los mensajes recientes, y el mensaje m√°s reciente del usuario:
  - Responde de manera c√°lida y emp√°tica.
  - Profundiza en los detalles mencionados en el mensaje reciente del usuario.
  - Si no hay nuevos detalles en el mensaje, utiliza el resumen o el historial para guiar la conversaci√≥n.
  - Formula una pregunta abierta que invite a compartir m√°s recuerdos, asegur√°ndote de no abrumar con demasiados temas.

  IMPORTANTE:
  - Personaliza la respuesta utilizando informaci√≥n relevante del resumen.
  - No repitas el historial directamente, pero √∫salo como contexto.
  - Prioriza un tono c√°lido, conversacional y curioso.
  `;
  if (completedCounter >= 3 && isCompleted) {
    userPrompt += `
    ----
    EXTRA: (considera esto solo si el usuario ya ha compartido suficiente informaci√≥n sobre su infancia) De todas formas debes seguir el sistema de preguntas del checklist, pero agrega un peque√±o mensaje que proponga y le pregunta si quiere que entremos en su etapa de adolescencia. 
    ejemplo: "... es emocionante hablar de tu adolescencia, me pregunto si quieres que comencemos a explorar tu etapa de adultez. ¬øQu√© te parece? 
    Puedes ser creativo en variar el mensaje, pero siempre respetando el tono c√°lido y emp√°tico.
    `;
  }

  console.log(userPrompt);

  try {
    const completion = await openai.chat.completions.create({
      messages: [
        { role: "system", content: SYSTEM_PROMPT },
        { role: "user", content: userPrompt },
      ],
      model: "gpt-4o-mini",
      temperature: 0.7,
      max_tokens: 500,
    });

    return (
      completion.choices[0]?.message?.content ||
      'Lo siento, no pude generar una respuesta adecuada.'
    );
  } catch (error) {
    console.error('Error al generar respuesta de IA:', error);
    return 'Lo siento, ocurri√≥ un error al procesar tu mensaje. Por favor, intenta de nuevo.';
  }
};



